# Day 18 â€” Agent Memory: Episodic, Vector, Task Memory + Routing & Context Pruning

## ğŸ”„ Connection to Day 17
Day 17 introduced **multi-agent systems** (specialized roles + supervising agent).  
But teams without memory are like coworkers with amnesia: they repeat work, forget decisions, and lose consistency.

Day 18 adds **memory layers** so agents can:
- remember **what happened** (episodic),
- remember **what weâ€™re doing** (task memory),
- remember **related knowledge** (vector memory),
- choose **which memory to use** (routing),
- and stay within token limits (**context pruning**).

---

## ğŸ§  Memory Types

### 1) Episodic Memory â€” â€œWhat happened?â€
A chronological log of important events:
- routing decisions,
- tool/agent inputs and outputs,
- errors,
- intermediate results.

**Why it matters**
- debugging (â€œwhy did the agent do that?â€),
- audits and traceability,
- evaluation and improvement.

Stored as: `day18_episodes*.json`

---

### 2) Task Memory â€” â€œWhat are we doing?â€
Task memory captures:
- the current goal,
- constraints and preferences,
- summaries of older conversation context,
- progress state (done / pending).

**Why it matters**
- consistent tone and structure,
- avoids repeating decisions,
- stabilizes multi-step workflows.

Stored as: `day18_task_memory*.json`

---

### 3) Vector Memory â€” â€œWhatâ€™s similar to this?â€
Vector memory stores embeddings for notes, summaries, and answers.  
Later, we use similarity search to recall semantically related items.

**Why it matters**
- recall works even without matching keywords,
- enables â€œsemantic recallâ€ (chunking â†” retrieval â†” embeddings),
- underpins memory-driven agents and RAG.

Stored as: `day18_vector_memory*.json`

---

## ğŸ§­ Memory Routing â€” â€œWhich memory should we use?â€
A common beginner mistake is: *dump all memory into the prompt*.  
That increases cost and can reduce accuracy.

Instead, we route:

- If user asks **â€œwhat did we do earlier / previous steps?â€**
  â†’ use **episodic memory**.
- If user asks **â€œremember style / tone / goal?â€**
  â†’ use **task memory**.
- Otherwise
  â†’ try **vector recall**.

Implemented in both `code.ts` and `framework.ts`.

---

## âœ‚ï¸ Context Pruning â€” â€œHow do we avoid context overflow?â€
Context windows are limited and tokens cost money.

We implement a pruning strategy:
- keep only the most recent N messages in **short-term memory**,
- summarize older messages into **task memory**,
- store that summary in vector memory so it can be recalled later.

This improves:
- latency,
- cost,
- and reduces â€œlost in contextâ€ failures.

---

## ğŸ“‚ Files
- `README.md` â€” this guide
- `code.ts` â€” Vanilla TypeScript (OpenAI HTTP calls + file-based memory)
- `framework.ts` â€” LangChain wrappers (ChatOpenAI + OpenAIEmbeddings)

---

## ğŸš€ package.json scripts

```jsonc
"dev:day18:vanilla": "tsx day18_agent_memory/code.ts",
"dev:day18:framework": "tsx day18_agent_memory/framework.ts"
```

---

## ğŸ”‘ .env
```bash
OPENAI_API_KEY=your_openai_key_here
```

---

## ğŸ“š References
- OpenAI Embeddings guide: https://platform.openai.com/docs/guides/embeddings
- OpenAI Function calling & tool patterns: https://platform.openai.com/docs/guides/function-calling
- LangChain JS docs: https://js.langchain.com/
- LangGraph (memory/state concepts): https://js.langchain.com/docs/langgraph/